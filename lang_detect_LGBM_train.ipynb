{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['hindi', 'tamil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('lang_detect_train.csv').fillna(' ')\n",
    "test = pd.read_csv('lang_detect_test.csv').fillna(' ')\n",
    "#test = pd.read_csv('lang_detect_bank.csv', encoding = \"ISO-8859-1\").fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hindi</th>\n",
       "      <th>tamil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188489</td>\n",
       "      <td>id28907</td>\n",
       "      <td>math welipaduch sudndratirgamaiya ethirfu paya...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81597</td>\n",
       "      <td>da3aa03d2f5c38c4</td>\n",
       "      <td>mesh raashi   bhagyonnati ke achche avasar pra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29813</td>\n",
       "      <td>4f2741560410793a</td>\n",
       "      <td>rajasthan lok seva garanti adhinium   ke tahat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67938</td>\n",
       "      <td>b5bdfe3c2a12ad56</td>\n",
       "      <td>jonpur yuva kisi bhi raashtra kii saamaajik or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90047</td>\n",
       "      <td>f0e8f46330543518</td>\n",
       "      <td>awaas ke anuroop shesh raashi jamaa karen haj ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0      188489           id28907   \n",
       "1       81597  da3aa03d2f5c38c4   \n",
       "2       29813  4f2741560410793a   \n",
       "3       67938  b5bdfe3c2a12ad56   \n",
       "4       90047  f0e8f46330543518   \n",
       "\n",
       "                                                text  hindi  tamil  \n",
       "0  math welipaduch sudndratirgamaiya ethirfu paya...    0.0    1.0  \n",
       "1  mesh raashi   bhagyonnati ke achche avasar pra...    1.0    0.0  \n",
       "2  rajasthan lok seva garanti adhinium   ke tahat...    1.0    0.0  \n",
       "3  jonpur yuva kisi bhi raashtra kii saamaajik or...    1.0    0.0  \n",
       "4  awaas ke anuroop shesh raashi jamaa karen haj ...    1.0    0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['text']\n",
    "test_text = test['text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word TFIDF 1/3\n",
      "Word TFIDF 2/3\n",
      "Word TFIDF 3/3\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000)\n",
    "word_vectorizer.fit(all_text)\n",
    "print('Word TFIDF 1/3')\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "print('Word TFIDF 2/3')\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "print('Word TFIDF 3/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_vectorizer = TfidfVectorizer(\n",
    "#     sublinear_tf=True,\n",
    "#     strip_accents='unicode',\n",
    "#     analyzer='char',\n",
    "#     ngram_range=(2, 6),\n",
    "#     max_features=50000)\n",
    "# char_vectorizer.fit(all_text)\n",
    "# print('Char TFIDF 1/3')\n",
    "# train_char_features = char_vectorizer.transform(train_text)\n",
    "# print('Char TFIDF 2/3')\n",
    "# test_char_features = char_vectorizer.transform(test_text)\n",
    "# print('Char TFIDF 3/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HStack 1/2\n",
      "HStack 2/2\n"
     ]
    }
   ],
   "source": [
    "train_features = hstack([train_word_features])\n",
    "print('HStack 1/2')\n",
    "test_features = hstack([test_word_features])\n",
    "print('HStack 2/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('text', axis=1, inplace=True)\n",
    "# del test\n",
    "# del train_text\n",
    "# del test_text\n",
    "# del all_text\n",
    "# del train_char_features\n",
    "# del test_char_features\n",
    "# del train_word_features\n",
    "# del test_word_features\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'text': test['text']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi\n",
      "(138159, 50000)\n",
      "(138159, 8436)\n",
      "[10]\ttraining's auc: 0.997789\tvalid_1's auc: 0.998314\n",
      "[20]\ttraining's auc: 0.999494\tvalid_1's auc: 0.999579\n",
      "[30]\ttraining's auc: 0.999757\tvalid_1's auc: 0.999765\n",
      "[40]\ttraining's auc: 0.999846\tvalid_1's auc: 0.999811\n",
      "[50]\ttraining's auc: 0.999891\tvalid_1's auc: 0.99982\n",
      "[60]\ttraining's auc: 0.999916\tvalid_1's auc: 0.999841\n",
      "[70]\ttraining's auc: 0.99993\tvalid_1's auc: 0.999848\n",
      "[80]\ttraining's auc: 0.999939\tvalid_1's auc: 0.999852\n",
      "tamil\n",
      "(138159, 50000)\n",
      "(138159, 8460)\n",
      "[10]\ttraining's auc: 0.997978\tvalid_1's auc: 0.99839\n",
      "[20]\ttraining's auc: 0.999512\tvalid_1's auc: 0.999538\n",
      "[30]\ttraining's auc: 0.999767\tvalid_1's auc: 0.99974\n",
      "[40]\ttraining's auc: 0.999849\tvalid_1's auc: 0.999785\n",
      "[50]\ttraining's auc: 0.999891\tvalid_1's auc: 0.999814\n"
     ]
    }
   ],
   "source": [
    "for class_name in class_names:\n",
    "    print(class_name)\n",
    "    train_target = train[class_name]\n",
    "    model = LogisticRegression(solver='sag')\n",
    "    sfm = SelectFromModel(model, threshold=0.2)\n",
    "    print(train_features.shape)\n",
    "    train_sparse_matrix = sfm.fit_transform(train_features, train_target)\n",
    "    print(train_sparse_matrix.shape)\n",
    "    train_sparse_matrix, valid_sparse_matrix, y_train, y_valid = train_test_split(train_sparse_matrix, train_target, test_size=0.05, random_state=144)\n",
    "    test_sparse_matrix = sfm.transform(test_features)\n",
    "    d_train = lgb.Dataset(train_sparse_matrix, label=y_train)\n",
    "    d_valid = lgb.Dataset(valid_sparse_matrix, label=y_valid)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    params = {'learning_rate': 0.2,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 31,\n",
    "              'verbosity': -1,\n",
    "              'metric': 'auc',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 4,\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 1}\n",
    "    rounds_lookup = {'hindi': 80,\n",
    "                 'tamil': 50}\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=rounds_lookup[class_name],\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=10)\n",
    "    submission[class_name] = model.predict(test_sparse_matrix)\n",
    "    # save the model to disk\n",
    "    filename = 'lang_detect_lgbmodel_'+class_name+'.txt'\n",
    "    #joblib.dump(model, filename)\n",
    "    model.save_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['truth_tamil'] = test['tamil']\n",
    "submission['truth_hindi'] = test['hindi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hindi</th>\n",
       "      <th>tamil</th>\n",
       "      <th>truth_tamil</th>\n",
       "      <th>truth_hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>processing fee iruka</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>0.973802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>enaku interest rate kami pana mudiyuma</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.986066</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>endha credit score neenga use panreenga</td>\n",
       "      <td>0.074277</td>\n",
       "      <td>0.960613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>promotion rates eydhachum offer iruka</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>0.973802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>unique benefits iruka</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>0.973802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>address epadi mathuradhu</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>0.973802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>fraud transaction eypadi tadukuradhu</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>0.973802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>credit card fraud policy ena</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.981434</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>phone number epadi mathuradhu</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>0.973802</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>credit card withdrawal limit ena</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.981434</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text     hindi     tamil  truth_tamil  \\\n",
       "146                     processing fee iruka  0.026888  0.973802            1   \n",
       "147  enaku interest rate kami pana mudiyuma   0.009561  0.986066            1   \n",
       "148  endha credit score neenga use panreenga  0.074277  0.960613            1   \n",
       "149   promotion rates eydhachum offer iruka   0.026888  0.973802            1   \n",
       "150                    unique benefits iruka  0.026888  0.973802            1   \n",
       "151                 address epadi mathuradhu  0.026888  0.973802            1   \n",
       "152     fraud transaction eypadi tadukuradhu  0.026888  0.973802            1   \n",
       "153            credit card fraud policy ena   0.004737  0.981434            1   \n",
       "154            phone number epadi mathuradhu  0.026888  0.973802            1   \n",
       "155         credit card withdrawal limit ena  0.004737  0.981434            1   \n",
       "\n",
       "     truth_hindi  \n",
       "146            0  \n",
       "147            0  \n",
       "148            0  \n",
       "149            0  \n",
       "150            0  \n",
       "151            0  \n",
       "152            0  \n",
       "153            0  \n",
       "154            0  \n",
       "155            0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lang_detect_result.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
