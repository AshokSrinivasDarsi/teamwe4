{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['hindi', 'tamil','english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('lang_detect_train.csv').fillna(' ')\n",
    "test = pd.read_csv('lang_detect_test.csv').fillna(' ')\n",
    "#test = pd.read_csv('lang_detect_bank.csv', encoding = \"ISO-8859-1\").fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hindi</th>\n",
       "      <th>tamil</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216406</td>\n",
       "      <td>id56852</td>\n",
       "      <td>in recent weeks as a result of a sweeping defe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143370</td>\n",
       "      <td>fec42bc28d73c346</td>\n",
       "      <td>pal pen adhikaries angalotu pengalukum cham ur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52271</td>\n",
       "      <td>8be632e20ed9bec6</td>\n",
       "      <td>rajasthan police kii consteble bhartee pariksh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10572</td>\n",
       "      <td>1be80c468c2fe3ce</td>\n",
       "      <td>aaj kai maheene baad mushtak kaa phone aayaa h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87462</td>\n",
       "      <td>ea0125a3a189f1a6</td>\n",
       "      <td>tamaam tarakkee ke baavjood duniya se garibi o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0      216406           id56852   \n",
       "1      143370  fec42bc28d73c346   \n",
       "2       52271  8be632e20ed9bec6   \n",
       "3       10572  1be80c468c2fe3ce   \n",
       "4       87462  ea0125a3a189f1a6   \n",
       "\n",
       "                                                text  hindi  tamil  english  \n",
       "0  in recent weeks as a result of a sweeping defe...      0      0        1  \n",
       "1  pal pen adhikaries angalotu pengalukum cham ur...      0      1        0  \n",
       "2  rajasthan police kii consteble bhartee pariksh...      1      0        0  \n",
       "3  aaj kai maheene baad mushtak kaa phone aayaa h...      1      0        0  \n",
       "4  tamaam tarakkee ke baavjood duniya se garibi o...      1      0        0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['text']\n",
    "test_text = test['text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word TFIDF 1/3\n",
      "Word TFIDF 2/3\n",
      "Word TFIDF 3/3\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000)\n",
    "word_vectorizer.fit(all_text)\n",
    "print('Word TFIDF 1/3')\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "print('Word TFIDF 2/3')\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "print('Word TFIDF 3/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_vectorizer = TfidfVectorizer(\n",
    "#     sublinear_tf=True,\n",
    "#     strip_accents='unicode',\n",
    "#     analyzer='char',\n",
    "#     ngram_range=(2, 6),\n",
    "#     max_features=50000)\n",
    "# char_vectorizer.fit(all_text)\n",
    "# print('Char TFIDF 1/3')\n",
    "# train_char_features = char_vectorizer.transform(train_text)\n",
    "# print('Char TFIDF 2/3')\n",
    "# test_char_features = char_vectorizer.transform(test_text)\n",
    "# print('Char TFIDF 3/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HStack 1/2\n",
      "HStack 2/2\n"
     ]
    }
   ],
   "source": [
    "train_features = hstack([train_word_features])\n",
    "print('HStack 1/2')\n",
    "test_features = hstack([test_word_features])\n",
    "print('HStack 2/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('text', axis=1, inplace=True)\n",
    "# del test\n",
    "# del train_text\n",
    "# del test_text\n",
    "# del all_text\n",
    "# del train_char_features\n",
    "# del test_char_features\n",
    "# del train_word_features\n",
    "# del test_word_features\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'text': test['text']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi\n",
      "(177934, 50000)\n",
      "(177934, 8758)\n",
      "[10]\ttraining's auc: 0.997357\tvalid_1's auc: 0.996783\n",
      "[20]\ttraining's auc: 0.99902\tvalid_1's auc: 0.998348\n",
      "[30]\ttraining's auc: 0.999512\tvalid_1's auc: 0.998899\n",
      "[40]\ttraining's auc: 0.999682\tvalid_1's auc: 0.999136\n",
      "[50]\ttraining's auc: 0.999772\tvalid_1's auc: 0.999253\n",
      "[60]\ttraining's auc: 0.999835\tvalid_1's auc: 0.999276\n",
      "[70]\ttraining's auc: 0.999868\tvalid_1's auc: 0.999307\n",
      "[80]\ttraining's auc: 0.999884\tvalid_1's auc: 0.999317\n",
      "tamil\n",
      "(177934, 50000)\n",
      "(177934, 12174)\n",
      "[10]\ttraining's auc: 0.994647\tvalid_1's auc: 0.994466\n",
      "[20]\ttraining's auc: 0.997343\tvalid_1's auc: 0.997218\n",
      "[30]\ttraining's auc: 0.998391\tvalid_1's auc: 0.998226\n",
      "[40]\ttraining's auc: 0.998883\tvalid_1's auc: 0.998749\n",
      "[50]\ttraining's auc: 0.999189\tvalid_1's auc: 0.999042\n",
      "english\n",
      "(177934, 50000)\n",
      "(177934, 10277)\n",
      "[10]\ttraining's auc: 0.994053\tvalid_1's auc: 0.994133\n",
      "[20]\ttraining's auc: 0.996651\tvalid_1's auc: 0.996398\n",
      "[30]\ttraining's auc: 0.997942\tvalid_1's auc: 0.997726\n"
     ]
    }
   ],
   "source": [
    "for class_name in class_names:\n",
    "    print(class_name)\n",
    "    train_target = train[class_name]\n",
    "    model = LogisticRegression(solver='sag')\n",
    "    sfm = SelectFromModel(model, threshold=0.2)\n",
    "    print(train_features.shape)\n",
    "    train_sparse_matrix = sfm.fit_transform(train_features, train_target)\n",
    "    print(train_sparse_matrix.shape)\n",
    "    train_sparse_matrix, valid_sparse_matrix, y_train, y_valid = train_test_split(train_sparse_matrix, train_target, test_size=0.05, random_state=144)\n",
    "    test_sparse_matrix = sfm.transform(test_features)\n",
    "    d_train = lgb.Dataset(train_sparse_matrix, label=y_train)\n",
    "    d_valid = lgb.Dataset(valid_sparse_matrix, label=y_valid)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    params = {'learning_rate': 0.2,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 31,\n",
    "              'verbosity': -1,\n",
    "              'metric': 'auc',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 4,\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 1}\n",
    "    rounds_lookup = {'hindi': 80,\n",
    "                 'tamil': 50,\n",
    "                 'english':30}\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=rounds_lookup[class_name],\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=10)\n",
    "    submission[class_name] = model.predict(test_sparse_matrix)\n",
    "    # save the model to disk\n",
    "    filename = 'lang_detect_lgbmodel_'+class_name+'.txt'\n",
    "    #joblib.dump(model, filename)\n",
    "    model.save_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['truth_tamil'] = test['tamil']\n",
    "submission['truth_hindi'] = test['hindi']\n",
    "submission['truth_english'] = test['english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hindi</th>\n",
       "      <th>tamil</th>\n",
       "      <th>english</th>\n",
       "      <th>truth_tamil</th>\n",
       "      <th>truth_hindi</th>\n",
       "      <th>truth_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to apply for home loan</td>\n",
       "      <td>0.016086</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.975755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are the Documents that are required for h...</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.982159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Is the Interest Rate and Annual Percentag...</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.986083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is There a Prepayment Penalty</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.982938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Much Time Do You Need to Fund</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.025521</td>\n",
       "      <td>0.908566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home loan eligibility</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.739912</td>\n",
       "      <td>0.355284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How to check my monthly emi</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>0.106045</td>\n",
       "      <td>0.895690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does tenure affect cost of loan</td>\n",
       "      <td>0.008564</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.909427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What security will i have to provide</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>0.975999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>maximum tenure for home loan</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.211217</td>\n",
       "      <td>0.888633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     hindi     tamil  \\\n",
       "0                         How to apply for home loan  0.016086  0.017944   \n",
       "1  what are the Documents that are required for h...  0.001600  0.005283   \n",
       "2  What Is the Interest Rate and Annual Percentag...  0.002231  0.004397   \n",
       "3                      Is There a Prepayment Penalty  0.000994  0.019650   \n",
       "4                  How Much Time Do You Need to Fund  0.005385  0.025521   \n",
       "5                              Home loan eligibility  0.052130  0.739912   \n",
       "6                        How to check my monthly emi  0.006831  0.106045   \n",
       "7                How does tenure affect cost of loan  0.008564  0.092150   \n",
       "8               What security will i have to provide  0.001396  0.022088   \n",
       "9                       maximum tenure for home loan  0.033517  0.211217   \n",
       "\n",
       "    english  truth_tamil  truth_hindi  truth_english  \n",
       "0  0.975755            0            0              1  \n",
       "1  0.982159            0            0              1  \n",
       "2  0.986083            0            0              1  \n",
       "3  0.982938            0            0              1  \n",
       "4  0.908566            0            0              1  \n",
       "5  0.355284            0            0              1  \n",
       "6  0.895690            0            0              1  \n",
       "7  0.909427            0            0              1  \n",
       "8  0.975999            0            0              1  \n",
       "9  0.888633            0            0              1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['lang_detected'] = submission[['hindi','tamil','english']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['actual_lang'] = submission[['truth_hindi','truth_tamil','truth_english']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'truth_english': 'english', 'truth_hindi': 'hindi', 'truth_tamil': 'tamil'}\n",
    "submission['actual_lang'] = submission['actual_lang'].map(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {'hindi':1,'tamil':2,'english':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['y_pred'] = submission['lang_detected'].map(lang)\n",
    "submission['actual'] = submission['actual_lang'].map(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hindi</th>\n",
       "      <th>tamil</th>\n",
       "      <th>english</th>\n",
       "      <th>truth_tamil</th>\n",
       "      <th>truth_hindi</th>\n",
       "      <th>truth_english</th>\n",
       "      <th>lang_detected</th>\n",
       "      <th>actual_lang</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to apply for home loan</td>\n",
       "      <td>0.016086</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.975755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>english</td>\n",
       "      <td>english</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are the Documents that are required for h...</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.982159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>english</td>\n",
       "      <td>english</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Is the Interest Rate and Annual Percentag...</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.986083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>english</td>\n",
       "      <td>english</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is There a Prepayment Penalty</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.982938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>english</td>\n",
       "      <td>english</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Much Time Do You Need to Fund</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.025521</td>\n",
       "      <td>0.908566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>english</td>\n",
       "      <td>english</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     hindi     tamil  \\\n",
       "0                         How to apply for home loan  0.016086  0.017944   \n",
       "1  what are the Documents that are required for h...  0.001600  0.005283   \n",
       "2  What Is the Interest Rate and Annual Percentag...  0.002231  0.004397   \n",
       "3                      Is There a Prepayment Penalty  0.000994  0.019650   \n",
       "4                  How Much Time Do You Need to Fund  0.005385  0.025521   \n",
       "\n",
       "    english  truth_tamil  truth_hindi  truth_english lang_detected  \\\n",
       "0  0.975755            0            0              1       english   \n",
       "1  0.982159            0            0              1       english   \n",
       "2  0.986083            0            0              1       english   \n",
       "3  0.982938            0            0              1       english   \n",
       "4  0.908566            0            0              1       english   \n",
       "\n",
       "  actual_lang  y_pred  actual  \n",
       "0     english       3       3  \n",
       "1     english       3       3  \n",
       "2     english       3       3  \n",
       "3     english       3       3  \n",
       "4     english       3       3  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycm import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu = np.array(submission['actual'])\n",
    "y_pred = np.array(submission['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pycm.ConfusionMatrix(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict  1        2        3        \n",
      "Actual\n",
      "1        41       10       1        \n",
      "\n",
      "2        0        52       0        \n",
      "\n",
      "3        0        2        50       \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (0.87329,0.96004)\n",
      "ACC Macro                                                         0.94444\n",
      "ARI                                                               0.76689\n",
      "AUNP                                                              0.9375\n",
      "AUNU                                                              0.9375\n",
      "Bangdiwala B                                                      0.84874\n",
      "Bennett S                                                         0.875\n",
      "CBA                                                               0.85417\n",
      "CSI                                                               0.84763\n",
      "Chi-Squared                                                       245.74265\n",
      "Chi-Squared DF                                                    4\n",
      "Conditional Entropy                                               0.35753\n",
      "Cramer V                                                          0.88749\n",
      "Cross Entropy                                                     1.60874\n",
      "F1 Macro                                                          0.91638\n",
      "F1 Micro                                                          0.91667\n",
      "FNR Macro                                                         0.08333\n",
      "FNR Micro                                                         0.08333\n",
      "FPR Macro                                                         0.04167\n",
      "FPR Micro                                                         0.04167\n",
      "Gwet AC1                                                          0.87526\n",
      "Hamming Loss                                                      0.08333\n",
      "Joint Entropy                                                     1.94249\n",
      "KL Divergence                                                     0.02378\n",
      "Kappa                                                             0.875\n",
      "Kappa 95% CI                                                      (0.80994,0.94006)\n",
      "Kappa No Prevalence                                               0.83333\n",
      "Kappa Standard Error                                              0.03319\n",
      "Kappa Unbiased                                                    0.87449\n",
      "Krippendorff Alpha                                                0.87489\n",
      "Lambda A                                                          0.875\n",
      "Lambda B                                                          0.8587\n",
      "Mutual Information                                                1.20382\n",
      "NIR                                                               0.33333\n",
      "Overall ACC                                                       0.91667\n",
      "Overall CEN                                                       0.16642\n",
      "Overall J                                                         (2.54436,0.84812)\n",
      "Overall MCC                                                       0.88226\n",
      "Overall MCEN                                                      0.24098\n",
      "Overall RACC                                                      0.33333\n",
      "Overall RACCU                                                     0.33607\n",
      "P-Value                                                           -0.0\n",
      "PPV Macro                                                         0.93096\n",
      "PPV Micro                                                         0.91667\n",
      "Pearson C                                                         0.78211\n",
      "Phi-Squared                                                       1.57527\n",
      "RCI                                                               0.75952\n",
      "RR                                                                52.0\n",
      "Reference Entropy                                                 1.58496\n",
      "Response Entropy                                                  1.56134\n",
      "SOA1(Landis & Koch)                                               Almost Perfect\n",
      "SOA2(Fleiss)                                                      Excellent\n",
      "SOA3(Altman)                                                      Very Good\n",
      "SOA4(Cicchetti)                                                   Excellent\n",
      "SOA5(Cramer)                                                      Very Strong\n",
      "SOA6(Matthews)                                                    Strong\n",
      "Scott PI                                                          0.87449\n",
      "Standard Error                                                    0.02213\n",
      "TNR Macro                                                         0.95833\n",
      "TNR Micro                                                         0.95833\n",
      "TPR Macro                                                         0.91667\n",
      "TPR Micro                                                         0.91667\n",
      "Zero-one Loss                                                     13\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           1             2             3             \n",
      "ACC(Accuracy)                                                     0.92949       0.92308       0.98077       \n",
      "AGF(Adjusted F-score)                                             0.87124       0.96518       0.974         \n",
      "AGM(Adjusted geometric mean)                                      0.93277       0.91817       0.98167       \n",
      "AM(Difference between automatic and manual classification)        -11           12            -1            \n",
      "AUC(Area under the ROC curve)                                     0.89423       0.94231       0.97596       \n",
      "AUCI(AUC value interpretation)                                    Very Good     Excellent     Excellent     \n",
      "AUPR(Area under the PR curve)                                     0.89423       0.90625       0.97097       \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.03526       0.03846       0.00321       \n",
      "BM(Informedness or bookmaker informedness)                        0.78846       0.88462       0.95192       \n",
      "CEN(Confusion entropy)                                            0.20813       0.20292       0.08767       \n",
      "DOR(Diagnostic odds ratio)                                        None          None          2575.0        \n",
      "DP(Discriminant power)                                            None          None          1.88046       \n",
      "DPI(Discriminant power interpretation)                            None          None          Limited       \n",
      "ERR(Error rate)                                                   0.07051       0.07692       0.01923       \n",
      "F0.5(F0.5 score)                                                  0.94907       0.84416       0.97656       \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.88172       0.89655       0.97087       \n",
      "F2(F2 score)                                                      0.82329       0.95588       0.96525       \n",
      "FDR(False discovery rate)                                         0.0           0.1875        0.01961       \n",
      "FN(False negative/miss/type 2 error)                              11            0             2             \n",
      "FNR(Miss rate or false negative rate)                             0.21154       0.0           0.03846       \n",
      "FOR(False omission rate)                                          0.09565       0.0           0.01905       \n",
      "FP(False positive/type 1 error/false alarm)                       0             12            1             \n",
      "FPR(Fall-out or false positive rate)                              0.0           0.11538       0.00962       \n",
      "G(G-measure geometric mean of precision and sensitivity)          0.88795       0.90139       0.97092       \n",
      "GI(Gini index)                                                    0.78846       0.88462       0.95192       \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          0.88795       0.94054       0.97585       \n",
      "IBA(Index of balanced accuracy)                                   0.62167       0.98669       0.92482       \n",
      "ICSI(Individual classification success index)                     0.78846       0.8125        0.94193       \n",
      "IS(Information score)                                             1.58496       1.2854        1.55639       \n",
      "J(Jaccard index)                                                  0.78846       0.8125        0.9434        \n",
      "LS(Lift score)                                                    3.0           2.4375        2.94118       \n",
      "MCC(Matthews correlation coefficient)                             0.84442       0.84779       0.95662       \n",
      "MCCI(Matthews correlation coefficient interpretation)             Strong        Strong        Very Strong   \n",
      "MCEN(Modified confusion entropy)                                  0.28351       0.28735       0.14324       \n",
      "MK(Markedness)                                                    0.90435       0.8125        0.96134       \n",
      "N(Condition negative)                                             104           104           104           \n",
      "NLR(Negative likelihood ratio)                                    0.21154       0.0           0.03883       \n",
      "NLRI(Negative likelihood ratio interpretation)                    Poor          Good          Good          \n",
      "NPV(Negative predictive value)                                    0.90435       1.0           0.98095       \n",
      "OC(Overlap coefficient)                                           1.0           1.0           0.98039       \n",
      "OOC(Otsuka-Ochiai coefficient)                                    0.88795       0.90139       0.97092       \n",
      "OP(Optimized precision)                                           0.81121       0.86185       0.96599       \n",
      "P(Condition positive or support)                                  52            52            52            \n",
      "PLR(Positive likelihood ratio)                                    None          8.66667       100.0         \n",
      "PLRI(Positive likelihood ratio interpretation)                    None          Fair          Good          \n",
      "POP(Population)                                                   156           156           156           \n",
      "PPV(Precision or positive predictive value)                       1.0           0.8125        0.98039       \n",
      "PRE(Prevalence)                                                   0.33333       0.33333       0.33333       \n",
      "Q(Yule Q - coefficient of colligation)                            None          None          0.99922       \n",
      "QI(Yule Q interpretation)                                         None          None          Strong        \n",
      "RACC(Random accuracy)                                             0.08761       0.13675       0.10897       \n",
      "RACCU(Random accuracy unbiased)                                   0.08885       0.13823       0.10898       \n",
      "TN(True negative/correct rejection)                               104           92            103           \n",
      "TNR(Specificity or true negative rate)                            1.0           0.88462       0.99038       \n",
      "TON(Test outcome negative)                                        115           92            105           \n",
      "TOP(Test outcome positive)                                        41            64            51            \n",
      "TP(True positive/hit)                                             41            52            50            \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         0.78846       1.0           0.96154       \n",
      "Y(Youden index)                                                   0.78846       0.88462       0.95192       \n",
      "dInd(Distance index)                                              0.21154       0.11538       0.03965       \n",
      "sInd(Similarity index)                                            0.85042       0.91841       0.97197       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lang_detect_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
