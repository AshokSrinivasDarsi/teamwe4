{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['hindi', 'tamil','english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('lang_detect_train.csv').fillna(' ')\n",
    "test = pd.read_csv('lang_detect_test.csv').fillna(' ')\n",
    "#test = pd.read_csv('lang_detect_bank.csv', encoding = \"ISO-8859-1\").fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hindi</th>\n",
       "      <th>tamil</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216406</td>\n",
       "      <td>id56852</td>\n",
       "      <td>in recent weeks as a result of a sweeping defe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143370</td>\n",
       "      <td>fec42bc28d73c346</td>\n",
       "      <td>pal pen adhikaries angalotu pengalukum cham ur...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52271</td>\n",
       "      <td>8be632e20ed9bec6</td>\n",
       "      <td>rajasthan police kii consteble bhartee pariksh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10572</td>\n",
       "      <td>1be80c468c2fe3ce</td>\n",
       "      <td>aaj kai maheene baad mushtak kaa phone aayaa h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87462</td>\n",
       "      <td>ea0125a3a189f1a6</td>\n",
       "      <td>tamaam tarakkee ke baavjood duniya se garibi o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0      216406           id56852   \n",
       "1      143370  fec42bc28d73c346   \n",
       "2       52271  8be632e20ed9bec6   \n",
       "3       10572  1be80c468c2fe3ce   \n",
       "4       87462  ea0125a3a189f1a6   \n",
       "\n",
       "                                                text  hindi  tamil  english  \n",
       "0  in recent weeks as a result of a sweeping defe...      0      0        1  \n",
       "1  pal pen adhikaries angalotu pengalukum cham ur...      0      1        0  \n",
       "2  rajasthan police kii consteble bhartee pariksh...      1      0        0  \n",
       "3  aaj kai maheene baad mushtak kaa phone aayaa h...      1      0        0  \n",
       "4  tamaam tarakkee ke baavjood duniya se garibi o...      1      0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['text']\n",
    "test_text = test['text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word TFIDF 1/3\n",
      "Word TFIDF 2/3\n",
      "Word TFIDF 3/3\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000)\n",
    "word_vectorizer.fit(all_text)\n",
    "print('Word TFIDF 1/3')\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "print('Word TFIDF 2/3')\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "print('Word TFIDF 3/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(word_vectorizer,open(\"feature.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_vectorizer = TfidfVectorizer(\n",
    "#     sublinear_tf=True,\n",
    "#     strip_accents='unicode',\n",
    "#     analyzer='char',\n",
    "#     ngram_range=(2, 6),\n",
    "#     max_features=50000)\n",
    "# char_vectorizer.fit(all_text)\n",
    "# print('Char TFIDF 1/3')\n",
    "# train_char_features = char_vectorizer.transform(train_text)\n",
    "# print('Char TFIDF 2/3')\n",
    "# test_char_features = char_vectorizer.transform(test_text)\n",
    "# print('Char TFIDF 3/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HStack 1/2\n",
      "HStack 2/2\n"
     ]
    }
   ],
   "source": [
    "train_features = hstack([train_word_features])\n",
    "print('HStack 1/2')\n",
    "test_features = hstack([test_word_features])\n",
    "print('HStack 2/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('text', axis=1, inplace=True)\n",
    "# del test\n",
    "# del train_text\n",
    "# del test_text\n",
    "# del all_text\n",
    "# del train_char_features\n",
    "# del test_char_features\n",
    "# del train_word_features\n",
    "# del test_word_features\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'text': test['text']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hindi\n",
      "(177934, 50000)\n",
      "(177934, 8747)\n",
      "[10]\ttraining's auc: 0.997339\tvalid_1's auc: 0.996231\n",
      "[20]\ttraining's auc: 0.999093\tvalid_1's auc: 0.99853\n",
      "[30]\ttraining's auc: 0.999486\tvalid_1's auc: 0.998954\n",
      "[40]\ttraining's auc: 0.999671\tvalid_1's auc: 0.999069\n",
      "[50]\ttraining's auc: 0.999769\tvalid_1's auc: 0.999138\n",
      "[60]\ttraining's auc: 0.999828\tvalid_1's auc: 0.999246\n",
      "[70]\ttraining's auc: 0.999862\tvalid_1's auc: 0.999309\n",
      "[80]\ttraining's auc: 0.999882\tvalid_1's auc: 0.999337\n",
      "tamil\n",
      "(177934, 50000)\n",
      "(177934, 12127)\n",
      "[10]\ttraining's auc: 0.994828\tvalid_1's auc: 0.994773\n",
      "[20]\ttraining's auc: 0.997486\tvalid_1's auc: 0.997313\n",
      "[30]\ttraining's auc: 0.998448\tvalid_1's auc: 0.998282\n",
      "[40]\ttraining's auc: 0.998894\tvalid_1's auc: 0.998766\n",
      "[50]\ttraining's auc: 0.999195\tvalid_1's auc: 0.999037\n",
      "english\n",
      "(177934, 50000)\n",
      "(177934, 10263)\n",
      "[10]\ttraining's auc: 0.994002\tvalid_1's auc: 0.994008\n",
      "[20]\ttraining's auc: 0.996961\tvalid_1's auc: 0.996676\n",
      "[30]\ttraining's auc: 0.99802\tvalid_1's auc: 0.997679\n"
     ]
    }
   ],
   "source": [
    "for class_name in class_names:\n",
    "    print(class_name)\n",
    "    train_target = train[class_name]\n",
    "    model = LogisticRegression(solver='sag')\n",
    "    sfm = SelectFromModel(model, threshold=0.2)\n",
    "    print(train_features.shape)\n",
    "    train_sparse_matrix = sfm.fit_transform(train_features, train_target)\n",
    "    print(train_sparse_matrix.shape)\n",
    "    pickle.dump(sfm,open(\"sfm\"+class_name+\".pkl\",\"wb\"))\n",
    "    train_sparse_matrix, valid_sparse_matrix, y_train, y_valid = train_test_split(train_sparse_matrix, train_target, test_size=0.05, random_state=144)\n",
    "    test_sparse_matrix = sfm.transform(test_features)\n",
    "    d_train = lgb.Dataset(train_sparse_matrix, label=y_train)\n",
    "    d_valid = lgb.Dataset(valid_sparse_matrix, label=y_valid)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    params = {'learning_rate': 0.2,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 31,\n",
    "              'verbosity': -1,\n",
    "              'metric': 'auc',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 4,\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 1}\n",
    "    rounds_lookup = {'hindi': 80,\n",
    "                 'tamil': 50,\n",
    "                 'english':30}\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=rounds_lookup[class_name],\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=10)\n",
    "    submission[class_name] = model.predict(test_sparse_matrix)\n",
    "    # save the model to disk\n",
    "    filename = 'lang_detect_lgbmodel_'+class_name+'.txt'\n",
    "    #joblib.dump(model, filename)\n",
    "    model.save_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['truth_tamil'] = test['tamil']\n",
    "submission['truth_hindi'] = test['hindi']\n",
    "submission['truth_english'] = test['english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hindi</th>\n",
       "      <th>tamil</th>\n",
       "      <th>english</th>\n",
       "      <th>truth_tamil</th>\n",
       "      <th>truth_hindi</th>\n",
       "      <th>truth_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pakistanin laguril watakits mansur sarmad aakh...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irai ulagil irutalana chalokatiskum iraivanukq...</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jo log kidney kii samasya hriday rog manovaigy...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>name</td>\n",
       "      <td>0.764252</td>\n",
       "      <td>0.227768</td>\n",
       "      <td>0.126948</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malamo chiruniro attak kalikk virumbhum andak ...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>home   india   koi chalati car par latak kar l...</td>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.029060</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>but what about our landing was lethal to the c...</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.993915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naan namee nallaa irukkuwants en vidu en kudum...</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.998448</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yasuki chaan jaise shaareerik chunautiyon se g...</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is saptaah aap kisi bijnes trip main ja sakate...</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     hindi     tamil  \\\n",
       "0  pakistanin laguril watakits mansur sarmad aakh...  0.000039  0.999826   \n",
       "1  irai ulagil irutalana chalokatiskum iraivanukq...  0.000292  0.999796   \n",
       "2  jo log kidney kii samasya hriday rog manovaigy...  0.999975  0.000186   \n",
       "3                                               name  0.764252  0.227768   \n",
       "4  malamo chiruniro attak kalikk virumbhum andak ...  0.000011  0.999907   \n",
       "5  home   india   koi chalati car par latak kar l...  0.997554  0.029060   \n",
       "6  but what about our landing was lethal to the c...  0.000157  0.002393   \n",
       "7  naan namee nallaa irukkuwants en vidu en kudum...  0.000933  0.998448   \n",
       "8  yasuki chaan jaise shaareerik chunautiyon se g...  0.999928  0.000425   \n",
       "9  is saptaah aap kisi bijnes trip main ja sakate...  0.999980  0.000094   \n",
       "\n",
       "    english  truth_tamil  truth_hindi  truth_english  \n",
       "0  0.001473            1            0              0  \n",
       "1  0.002762            1            0              0  \n",
       "2  0.000730            0            1              0  \n",
       "3  0.126948            0            1              0  \n",
       "4  0.000522            1            0              0  \n",
       "5  0.001546            0            1              0  \n",
       "6  0.993915            0            0              1  \n",
       "7  0.003000            1            0              0  \n",
       "8  0.000541            0            1              0  \n",
       "9  0.000587            0            1              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['lang_detected'] = submission[['hindi','tamil','english']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['actual_lang'] = submission[['truth_hindi','truth_tamil','truth_english']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'truth_english': 'english', 'truth_hindi': 'hindi', 'truth_tamil': 'tamil'}\n",
    "submission['actual_lang'] = submission['actual_lang'].map(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {'hindi':1,'tamil':2,'english':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['y_pred'] = submission['lang_detected'].map(lang)\n",
    "submission['actual'] = submission['actual_lang'].map(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hindi</th>\n",
       "      <th>tamil</th>\n",
       "      <th>english</th>\n",
       "      <th>truth_tamil</th>\n",
       "      <th>truth_hindi</th>\n",
       "      <th>truth_english</th>\n",
       "      <th>lang_detected</th>\n",
       "      <th>actual_lang</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pakistanin laguril watakits mansur sarmad aakh...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tamil</td>\n",
       "      <td>tamil</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irai ulagil irutalana chalokatiskum iraivanukq...</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tamil</td>\n",
       "      <td>tamil</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jo log kidney kii samasya hriday rog manovaigy...</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hindi</td>\n",
       "      <td>hindi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>name</td>\n",
       "      <td>0.764252</td>\n",
       "      <td>0.227768</td>\n",
       "      <td>0.126948</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hindi</td>\n",
       "      <td>hindi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malamo chiruniro attak kalikk virumbhum andak ...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tamil</td>\n",
       "      <td>tamil</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     hindi     tamil  \\\n",
       "0  pakistanin laguril watakits mansur sarmad aakh...  0.000039  0.999826   \n",
       "1  irai ulagil irutalana chalokatiskum iraivanukq...  0.000292  0.999796   \n",
       "2  jo log kidney kii samasya hriday rog manovaigy...  0.999975  0.000186   \n",
       "3                                               name  0.764252  0.227768   \n",
       "4  malamo chiruniro attak kalikk virumbhum andak ...  0.000011  0.999907   \n",
       "\n",
       "    english  truth_tamil  truth_hindi  truth_english lang_detected  \\\n",
       "0  0.001473            1            0              0         tamil   \n",
       "1  0.002762            1            0              0         tamil   \n",
       "2  0.000730            0            1              0         hindi   \n",
       "3  0.126948            0            1              0         hindi   \n",
       "4  0.000522            1            0              0         tamil   \n",
       "\n",
       "  actual_lang  y_pred  actual  \n",
       "0       tamil       2       2  \n",
       "1       tamil       2       2  \n",
       "2       hindi       1       1  \n",
       "3       hindi       1       1  \n",
       "4       tamil       2       2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycm import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu = np.array(submission['actual'])\n",
    "y_pred = np.array(submission['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict     1           2           3           \n",
      "Actual\n",
      "1           29498       184         57          \n",
      "\n",
      "2           66          29001       333         \n",
      "\n",
      "3           18          759         16342       \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (0.98046,0.98238)\n",
      "ACC Macro                                                         0.98761\n",
      "ARI                                                               0.94889\n",
      "AUNP                                                              0.98574\n",
      "AUNU                                                              0.98407\n",
      "Bangdiwala B                                                      0.96664\n",
      "Bennett S                                                         0.97213\n",
      "CBA                                                               0.97167\n",
      "CSI                                                               0.95843\n",
      "Chi-Squared                                                       143228.08292\n",
      "Chi-Squared DF                                                    4\n",
      "Conditional Entropy                                               0.13377\n",
      "Cramer V                                                          0.96907\n",
      "Cross Entropy                                                     1.54396\n",
      "F1 Macro                                                          0.97914\n",
      "F1 Micro                                                          0.98142\n",
      "FNR Macro                                                         0.02235\n",
      "FNR Micro                                                         0.01858\n",
      "FPR Macro                                                         0.00951\n",
      "FPR Micro                                                         0.00929\n",
      "Gwet AC1                                                          0.97251\n",
      "Hamming Loss                                                      0.01858\n",
      "Joint Entropy                                                     1.67754\n",
      "KL Divergence                                                     0.00019\n",
      "Kappa                                                             0.97133\n",
      "Kappa 95% CI                                                      (0.96985,0.97281)\n",
      "Kappa No Prevalence                                               0.96284\n",
      "Kappa Standard Error                                              0.00075\n",
      "Kappa Unbiased                                                    0.97133\n",
      "Krippendorff Alpha                                                0.97133\n",
      "Lambda A                                                          0.96954\n",
      "Lambda B                                                          0.9694\n",
      "Mutual Information                                                1.40589\n",
      "NIR                                                               0.38998\n",
      "Overall ACC                                                       0.98142\n",
      "Overall CEN                                                       0.06395\n",
      "Overall J                                                         (2.87822,0.95941)\n",
      "Overall MCC                                                       0.97139\n",
      "Overall MCEN                                                      0.10798\n",
      "Overall RACC                                                      0.35192\n",
      "Overall RACCU                                                     0.35194\n",
      "P-Value                                                           None\n",
      "PPV Macro                                                         0.98079\n",
      "PPV Micro                                                         0.98142\n",
      "Pearson C                                                         0.80781\n",
      "Phi-Squared                                                       1.8782\n",
      "RCI                                                               0.91069\n",
      "RR                                                                25419.33333\n",
      "Reference Entropy                                                 1.54377\n",
      "Response Entropy                                                  1.53966\n",
      "SOA1(Landis & Koch)                                               Almost Perfect\n",
      "SOA2(Fleiss)                                                      Excellent\n",
      "SOA3(Altman)                                                      Very Good\n",
      "SOA4(Cicchetti)                                                   Excellent\n",
      "SOA5(Cramer)                                                      Very Strong\n",
      "SOA6(Matthews)                                                    Very Strong\n",
      "Scott PI                                                          0.97133\n",
      "Standard Error                                                    0.00049\n",
      "TNR Macro                                                         0.99049\n",
      "TNR Micro                                                         0.99071\n",
      "TPR Macro                                                         0.97765\n",
      "TPR Micro                                                         0.98142\n",
      "Zero-one Loss                                                     1417\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           1             2             3             \n",
      "ACC(Accuracy)                                                     0.99574       0.9824        0.9847        \n",
      "AGF(Adjusted F-score)                                             0.99422       0.98592       0.97348       \n",
      "AGM(Adjusted geometric mean)                                      0.99624       0.9819        0.98237       \n",
      "AM(Difference between automatic and manual classification)        -157          544           -387          \n",
      "AUC(Area under the ROC curve)                                     0.99505       0.98315       0.97401       \n",
      "AUCI(AUC value interpretation)                                    Excellent     Excellent     Excellent     \n",
      "AUPR(Area under the PR curve)                                     0.99453       0.97747       0.96565       \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.00103       0.00357       0.00254       \n",
      "BM(Informedness or bookmaker informedness)                        0.99009       0.9663        0.94802       \n",
      "CEN(Confusion entropy)                                            0.02497       0.07957       0.10487       \n",
      "DOR(Diagnostic odds ratio)                                        67661.51107   3539.01965    3168.25449    \n",
      "DP(Discriminant power)                                            2.66311       1.9566        1.9301        \n",
      "DPI(Discriminant power interpretation)                            Fair          Limited       Limited       \n",
      "ERR(Error rate)                                                   0.00426       0.0176        0.0153        \n",
      "F0.5(F0.5 score)                                                  0.9961        0.97204       0.97219       \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.99452       0.97739       0.96553       \n",
      "F2(F2 score)                                                      0.99294       0.98279       0.95895       \n",
      "FDR(False discovery rate)                                         0.00284       0.03149       0.02331       \n",
      "FN(False negative/miss/type 2 error)                              241           399           777           \n",
      "FNR(Miss rate or false negative rate)                             0.0081        0.01357       0.04539       \n",
      "FOR(False omission rate)                                          0.00516       0.00862       0.01305       \n",
      "FP(False positive/type 1 error/false alarm)                       84            943           390           \n",
      "FPR(Fall-out or false positive rate)                              0.00181       0.02012       0.00659       \n",
      "G(G-measure geometric mean of precision and sensitivity)          0.99452       0.97743       0.96559       \n",
      "GI(Gini index)                                                    0.99009       0.9663        0.94802       \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          0.99504       0.98315       0.97382       \n",
      "IBA(Index of balanced accuracy)                                   0.98387       0.97291       0.91153       \n",
      "ICSI(Individual classification success index)                     0.98906       0.95494       0.9313        \n",
      "IS(Information score)                                             1.35443       1.32891       2.12126       \n",
      "J(Jaccard index)                                                  0.9891        0.95577       0.93335       \n",
      "LS(Lift score)                                                    2.55696       2.51212       4.35075       \n",
      "MCC(Matthews correlation coefficient)                             0.99104       0.96309       0.9558        \n",
      "MCCI(Matthews correlation coefficient interpretation)             Very Strong   Very Strong   Very Strong   \n",
      "MCEN(Modified confusion entropy)                                  0.04426       0.13422       0.17105       \n",
      "MK(Markedness)                                                    0.992         0.95989       0.96364       \n",
      "N(Condition negative)                                             46519         46858         59139         \n",
      "NLR(Negative likelihood ratio)                                    0.00812       0.01385       0.04569       \n",
      "NLRI(Negative likelihood ratio interpretation)                    Good          Good          Good          \n",
      "NPV(Negative predictive value)                                    0.99484       0.99138       0.98695       \n",
      "OC(Overlap coefficient)                                           0.99716       0.98643       0.97669       \n",
      "OOC(Otsuka-Ochiai coefficient)                                    0.99452       0.97743       0.96559       \n",
      "OP(Optimized precision)                                           0.99257       0.97907       0.96478       \n",
      "P(Condition positive or support)                                  29739         29400         17119         \n",
      "PLR(Positive likelihood ratio)                                    549.30973     49.01598      144.75587     \n",
      "PLRI(Positive likelihood ratio interpretation)                    Good          Good          Good          \n",
      "POP(Population)                                                   76258         76258         76258         \n",
      "PPV(Precision or positive predictive value)                       0.99716       0.96851       0.97669       \n",
      "PRE(Prevalence)                                                   0.38998       0.38553       0.22449       \n",
      "Q(Yule Q - coefficient of colligation)                            0.99997       0.99944       0.99937       \n",
      "QI(Yule Q interpretation)                                         Strong        Strong        Strong        \n",
      "RACC(Random accuracy)                                             0.15128       0.15139       0.04926       \n",
      "RACCU(Random accuracy unbiased)                                   0.15128       0.1514        0.04926       \n",
      "TN(True negative/correct rejection)                               46435         45915         58749         \n",
      "TNR(Specificity or true negative rate)                            0.99819       0.97988       0.99341       \n",
      "TON(Test outcome negative)                                        46676         46314         59526         \n",
      "TOP(Test outcome positive)                                        29582         29944         16732         \n",
      "TP(True positive/hit)                                             29498         29001         16342         \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         0.9919        0.98643       0.95461       \n",
      "Y(Youden index)                                                   0.99009       0.9663        0.94802       \n",
      "dInd(Distance index)                                              0.0083        0.02427       0.04586       \n",
      "sInd(Similarity index)                                            0.99413       0.98284       0.96757       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lang_detect_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
