{
  "inform": {
    "precision": 0.788235294117647,
    "recall": 0.8589743589743589,
    "f1-score": 0.8220858895705521,
    "support": 78,
    "confused_with": {
      "pay_cc": 4,
      "check_balance": 3
    }
  },
  "ask_transfer_charge": {
    "precision": 0.4,
    "recall": 0.2222222222222222,
    "f1-score": 0.2857142857142857,
    "support": 9,
    "confused_with": {
      "check_balance": 4,
      "transfer_money": 1
    }
  },
  "affirm": {
    "precision": 1.0,
    "recall": 0.06666666666666667,
    "f1-score": 0.125,
    "support": 15,
    "confused_with": {
      "inform": 5,
      "greet": 3,
      "deny": 2
    }
  },
  "check_earnings": {
    "precision": 0.7,
    "recall": 0.5384615384615384,
    "f1-score": 0.608695652173913,
    "support": 13,
    "confused_with": {
      "check_recipients": 4,
      "check_balance": 2
    }
  },
  "deny": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 10,
    "confused_with": {
      "inform": 7,
      "help": 1,
      "greet": 1
    }
  },
  "transfer_money": {
    "precision": 0.9375,
    "recall": 0.4166666666666667,
    "f1-score": 0.5769230769230769,
    "support": 36,
    "confused_with": {
      "pay_cc": 20,
      "inform": 1
    }
  },
  "goodbye": {
    "precision": 1.0,
    "recall": 0.1,
    "f1-score": 0.18181818181818182,
    "support": 10,
    "confused_with": {
      "greet": 5,
      "thankyou": 1,
      "inform": 1
    }
  },
  "help": {
    "precision": 0.5,
    "recall": 0.1,
    "f1-score": 0.16666666666666669,
    "support": 10,
    "confused_with": {
      "check_recipients": 4,
      "check_balance": 3,
      "greet": 2
    }
  },
  "greet": {
    "precision": 0.44,
    "recall": 0.55,
    "f1-score": 0.48888888888888893,
    "support": 20,
    "confused_with": {
      "deny": 7,
      "check_recipients": 1
    }
  },
  "thankyou": {
    "precision": 0.8571428571428571,
    "recall": 0.5454545454545454,
    "f1-score": 0.6666666666666665,
    "support": 11,
    "confused_with": {
      "deny": 2,
      "inform": 1
    }
  },
  "check_balance": {
    "precision": 0.6724137931034483,
    "recall": 0.8297872340425532,
    "f1-score": 0.7428571428571429,
    "support": 47,
    "confused_with": {
      "check_recipients": 3,
      "inform": 2
    }
  },
  "check_recipients": {
    "precision": 0.3103448275862069,
    "recall": 0.6923076923076923,
    "f1-score": 0.4285714285714286,
    "support": 13,
    "confused_with": {
      "check_earnings": 2,
      "pay_cc": 1
    }
  },
  "search_transactions": {
    "precision": 0.85,
    "recall": 0.7391304347826086,
    "f1-score": 0.7906976744186046,
    "support": 23,
    "confused_with": {
      "check_balance": 4,
      "pay_cc": 1
    }
  },
  "human_handoff": {
    "precision": 0.5,
    "recall": 0.1111111111111111,
    "f1-score": 0.1818181818181818,
    "support": 9,
    "confused_with": {
      "search_transactions": 2,
      "pay_cc": 2,
      "check_recipients": 2
    }
  },
  "pay_cc": {
    "precision": 0.5161290322580645,
    "recall": 0.9696969696969697,
    "f1-score": 0.6736842105263158,
    "support": 33,
    "confused_with": {
      "check_recipients": 1
    }
  },
  "accuracy": 0.6201780415430267,
  "macro avg": {
    "precision": 0.6314510536138817,
    "recall": 0.4493652960257955,
    "f1-score": 0.449339196440927,
    "support": 337
  },
  "weighted avg": {
    "precision": 0.691041879729219,
    "recall": 0.6201780415430267,
    "f1-score": 0.594620371461297,
    "support": 337
  }
}